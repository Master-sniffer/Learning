{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"05_data_files_2_Фамилия_Имя.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"d1XSokU4Z8V7"},"source":["# Форматы данных (2)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RfxBFhIZ-8U","executionInfo":{"status":"ok","timestamp":1633960626664,"user_tz":-180,"elapsed":6,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"f4e1458f-e835-46e4-c798-15929c48bfca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"JHgOIvuyZ8WA"},"source":["Материалы:\n","* Макрушин С.В. \"Лекция 5: Форматы данных (часть 2)\"\n","* https://docs.python.org/3/library/csv.html\n","* https://docs.h5py.org/en/stable/\n","* Уэс Маккини. Python и анализ данных"]},{"cell_type":"markdown","metadata":{"id":"bbkMe8z-Z8WB"},"source":["## Задачи для совместного разбора"]},{"cell_type":"markdown","metadata":{"id":"tfeEx4NuZ8WC"},"source":["1. Считайте данные из файла `open_pubs.csv`, используя `csv.reader`, и преобразуйте к структуре данных следующего вида:\n","    \n","`{'fas_id': [24, 30, ...], 'name': ['Achor Inn', 'Angel Inn', ...], ... }`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-mV8LBGeaIH","executionInfo":{"status":"ok","timestamp":1633353883367,"user_tz":-180,"elapsed":306,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"16fcc94f-36fc-443e-f4d7-d5c29ca57746"},"source":["import csv\n"," \n","with open('/content/drive/MyDrive/Colab Notebooks/lab 5/open_pubs.csv') as fp:\n","    reader = csv.reader(fp)\n","    header = next(reader)\n","    \n","    for row in reader:\n","        print(row)\n","        break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['24', 'Anchor Inn', 'Upper Street, Stratford St Mary, COLCHESTER, Essex', 'CO7 6LW', '604748', '234405', '51.97039', '0.979328', 'Babergh']\n"]}]},{"cell_type":"markdown","metadata":{"id":"zhMAcBm2Z8WC"},"source":["2. Сгенерируйте 2 случайные матрицы размера 10_000 x 10_000 и вычислите их произведение. Сколько времени занимают три этих операции? Сохраните 3 полученных матрицы в файл .npz с соответствующими названиями"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O73GegnweaXk","executionInfo":{"status":"ok","timestamp":1633353921448,"user_tz":-180,"elapsed":32938,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"7a47f722-78b1-4ba5-f6c7-3a1f6055c00e"},"source":["import numpy as np\n"," \n","A = np.random.randint(0, 100, size=(10_000, 10_000))\n","B = np.random.randint(0, 100, size=(10_000, 10_000))\n"," \n","np.save('A.npy', A)\n","np.savez('AB.npz', A, B)\n"," \n","r = np.load('AB.npz')\n","print(r.files)\n"," \n","r['arr_0']\n"," \n","A.dtype\n"," \n","10_000 * 10_000 * 4 / 1024 / 1024"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['arr_0', 'arr_1']\n"]},{"output_type":"execute_result","data":{"text/plain":["381.4697265625"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"NTeACUJkZ8WD"},"source":["3. Создайте 2 матрицы размера 1000x1000, используя различные параметризируемые распределения из numpy (https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html#distributions)\n","\n","После этого сохраните получившиеся матрицы в hdf5-файл в виде двух различных датасетов. В качестве описания каждого датасета укажите параметры используемых распределений "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":600},"id":"jbhx3s9Heb7p","executionInfo":{"status":"error","timestamp":1633353958693,"user_tz":-180,"elapsed":27937,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"e636e59c-9251-4dfd-bb96-f57fbdc97118"},"source":["import h5py\n"," \n","with h5py.File('test.h5', 'w') as hdf:\n","    ds1 = hdf.create_dataset('arrA', data=A)\n","    ds2 = hdf.create_dataset('arrB', data=B)\n","    \n","    ds1.attrs['description'] = 'Здесь лежит массив А'\n"," \n","with h5py.File('test.h5', 'r') as hdf:\n","    ds1 = hdf['arrA']\n","    print(type(ds1))\n","    arr = ds1[:100]\n","# ..\n"," \n","ds1[:100]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'h5py._hl.dataset.Dataset'>\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0e0d80b22339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mds1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_read_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fast_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Fall back to Python read pathway below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m_fast_reader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_props\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_fast_reader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mrdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# If the file is read-only, cache the reader to speed up future uses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_selector.pyx\u001b[0m in \u001b[0;36mh5py._selector.Reader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.get_space\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid dataset identifier (invalid dataset identifier)"]}]},{"cell_type":"markdown","metadata":{"id":"i2kJhrQkZ8WE"},"source":["## Лабораторная работа 5"]},{"cell_type":"markdown","metadata":{"id":"G7AaArsqZ8WE"},"source":["### csv"]},{"cell_type":"markdown","metadata":{"id":"pZ5qO_B-Z8WF"},"source":["1.1 В файле `tags_sample.csv` находится информация о тэгах, приписываемых рецептам. Воспользовавшись `csv.reader`, считайте этот файл и создайте словарь вида `id_рецепта: [список тэгов]`. Сохраните этот словарь в файл `tags_sample.json`."]},{"cell_type":"code","metadata":{"id":"SxuogoPicdJw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633960640458,"user_tz":-180,"elapsed":1024,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"cf7b7418-04cb-4d75-8005-ae2cee533887"},"source":["import csv\n","import json\n","\n","\n","data_dict = {}\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/lab 5/tags_sample.csv') as file:\n","    reader = csv.reader(file)\n","    header = next(reader)\n","    print(header)\n","    for row in reader:\n","        \n","        item_id = int(row[0])\n","        item_tag = row[1]\n","        \n","        if item_id not in data_dict:\n","            data_dict[item_id] = []\n","        data_dict[item_id].append(item_tag)"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["['id', 'tag']\n"]}]},{"cell_type":"markdown","metadata":{"id":"9__G0KPjZ8WG"},"source":["1.2 Считайте файл `recipes_sample_with_filled_nsteps.csv` (__ЛР4__) в виде `pd.DataFrame`. Добавьте к таблице 2 столбца: `n_tags`, содержащий количество тэгов у этого рецепта; и `tags`, содержащий набор тэгов в виде строки (тэги внутри строки разделяются символом `;`)"]},{"cell_type":"code","metadata":{"id":"9XH_WMYHcdsw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959345757,"user_tz":-180,"elapsed":1939,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"2115210b-01a8-4434-94a4-82082f121be0"},"source":["with open(\"/content/result.json\", \"w\") as file:\n","    json.dump(data_dict, file)\n","\n","with open(\"/content/result.json\", \"r\") as file:\n","    data_dict_new = json.load(file)\n","\n","\n","\n","import pandas as pd\n","\n","recipes_filled = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/lab 4/recipes_sample_with_filled_nsteps.csv\")\n","#print(recipes_filled)\n","\n","\n","patched_dict = {k : len(v) for (k,v) in data_dict.items()}\n","\n","def filler(x):\n","    if x[\"id\"] in patched_dict:\n","        return patched_dict[x[\"id\"]] \n","    return float(\"nan\")\n","    \n","recipes_filled['n_tags'] = recipes_filled.apply(lambda x: filler(x), axis=1)\n","\n","\n","print(recipes_filled)\n","\n","patched_dict = {k : \";\".join(v) for (k,v) in data_dict.items()}\n","\n","print(patched_dict)\n","\n","\n","\n","def filler(x):\n","    if x[\"id\"] in patched_dict:\n","        return patched_dict[x[\"id\"]]\n","    return float(\"nan\")\n","\n","recipes_filled['tags'] = recipes_filled.apply(lambda x: filler(x), axis=1)\n","\n","\n","print(recipes_filled)\n","\n","print (recipes_filled[recipes_filled['n_tags'].isna()] )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]},{"output_type":"stream","name":"stdout","text":["           id  ...                                               tags\n","0       44123  ...  unsalted butter;carrot;onion;celery;broccoli s...\n","1       67664  ...         milk;frozen juice concentrate;plain yogurt\n","2       38798  ...  onion;frozen chopped spinach;eggs;garlic powde...\n","3       35173  ...  sandwich bun;good seasonings italian salad dre...\n","4       84797  ...  beef steaks;vegetable oil;spicy mustard;fresh ...\n","...       ...  ...                                                ...\n","29995  267661  ...  dry white wine;eggs;cheddar cheese;baking powd...\n","29996  386977  ...  unsalted butter;milk;flour;salt;vanilla;all-pu...\n","29997  103312  ...  onion;milk;eggs;butter;flour;salt;pepper;sugar...\n","29998  486161  ...  onion;celery;dried thyme;dried oregano;fresh p...\n","29999  298512  ...  butter;sour cream;egg;bisquick;light brown sug...\n","\n","[30000 rows x 10 columns]\n","Empty DataFrame\n","Columns: [id, name, minutes, contributor_id, submitted, n_steps, description, n_ingredients, n_tags, tags]\n","Index: []\n"]}]},{"cell_type":"markdown","metadata":{"id":"1m2xNEZLZ8WG"},"source":["1.3 В файле `ingredients_sample.csv` находится информация о ингредиентах, необходимых для рецепта. Воспользовавшись `csv.DictReader`, считайте этот файл и создайте словарь вида `id_рецепта: [список ингредиентов]`."]},{"cell_type":"code","metadata":{"id":"YlxT_yWNceWX"},"source":["data_dict = {}\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/lab 5/ingredients_sample.csv') as file:\n","    reader = csv.DictReader(file)\n","    for item in reader:\n","        ingredient, recipe_id = item[\"ingredient\"], int(item[\"recipe_id\"])\n","\n","        if recipe_id not in data_dict:\n","            data_dict[recipe_id] = []\n","        data_dict[recipe_id].append(ingredient)\n","\n","        \n","data_dict\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJ2NT58sZ8WH"},"source":["1.4 Добавьте к таблице из задания 1.2 столбец `ingredients`, содержащий набор ингредиентов в виде строки (ингредиенты внутри строки разделяются символом `*`)\n","\n","Для строк, которые содержат пропуски в столбце `n_ingredients`, заполните их на основе файла  `ingredients_sample.csv`"]},{"cell_type":"code","metadata":{"id":"tsUWYZmwcfQZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633961052993,"user_tz":-180,"elapsed":1391,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"af2017bd-a729-4cab-e382-0cd5f83057bd"},"source":["import pandas as pd\n","\n","patched_dict = {k : \"*\".join(v) for k, v in data_dict.items()}\n","\n","def filler(x):\n","    if x[\"id\"] in patched_dict:\n","        return patched_dict[x[\"id\"]]\n","    return float(\"nan\")\n","    \n","recipes_filled['ingredients'] = recipes_filled.apply(lambda x: filler(x), axis=1)\n","\n","\n","print (recipes_filled)\n","\n","\n","patched_dict = {k : len(v) for k, v in data_dict.items()}\n","\n","\n","def filler(x):\n","    if pd.isna(x[\"n_ingredients\"]) and x[\"id\"] in patched_dict:\n","        return patched_dict[x[\"id\"]]\n","    return x[\"n_ingredients\"]\n","\n","recipes_filled['n_ingredients'] = recipes_filled.apply(lambda x: filler(x), axis=1)\n","\n","\n","print (recipes_filled)\n","\n"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["           id  ...                                        ingredients\n","0       44123  ...  weeknight*time-to-make*course*main-ingredient*...\n","1       67664  ...  15-minutes-or-less*time-to-make*course*prepara...\n","2       38798  ...  30-minutes-or-less*time-to-make*course*main-in...\n","3       35173  ...  60-minutes-or-less*time-to-make*course*prepara...\n","4       84797  ...  30-minutes-or-less*time-to-make*course*main-in...\n","...       ...  ...                                                ...\n","29995  267661  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29996  386977  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29997  103312  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29998  486161  ...  ham*60-minutes-or-less*time-to-make*course*mai...\n","29999  298512  ...  30-minutes-or-less*time-to-make*course*prepara...\n","\n","[30000 rows x 11 columns]\n","           id  ...                                        ingredients\n","0       44123  ...  weeknight*time-to-make*course*main-ingredient*...\n","1       67664  ...  15-minutes-or-less*time-to-make*course*prepara...\n","2       38798  ...  30-minutes-or-less*time-to-make*course*main-in...\n","3       35173  ...  60-minutes-or-less*time-to-make*course*prepara...\n","4       84797  ...  30-minutes-or-less*time-to-make*course*main-in...\n","...       ...  ...                                                ...\n","29995  267661  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29996  386977  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29997  103312  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29998  486161  ...  ham*60-minutes-or-less*time-to-make*course*mai...\n","29999  298512  ...  30-minutes-or-less*time-to-make*course*prepara...\n","\n","[30000 rows x 11 columns]\n"]}]},{"cell_type":"markdown","metadata":{"id":"xLcMaLhEZ8WJ"},"source":["1.5 Проверьте, содержит ли столбец `n_ingredients` пропуски. Если нет, треобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_tags_ingredients.csv`"]},{"cell_type":"code","metadata":{"id":"cwiru5LLchPr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633961096008,"user_tz":-180,"elapsed":1663,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"f470265c-4f96-4ecf-a929-77e170d0cded"},"source":["recipes_filled[recipes_filled[\"n_ingredients\"].isnull()]\n","\n","\n","recipes_filled[\"n_ingredients\"] = recipes_filled[\"n_ingredients\"].astype(int)\n","\n","\n","print(recipes_filled.dtypes)\n","\n","print (recipes_filled)\n","\n","recipes_filled.to_csv(\"./recipes_sample_with_tags_ingredients.csv\")"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["id                         int64\n","name                      object\n","minutes                    int64\n","contributor_id             int64\n","submitted         datetime64[ns]\n","n_steps                    int64\n","description               object\n","n_ingredients              int64\n","n_tags                     int64\n","tags                      object\n","ingredients               object\n","dtype: object\n","           id  ...                                        ingredients\n","0       44123  ...  weeknight*time-to-make*course*main-ingredient*...\n","1       67664  ...  15-minutes-or-less*time-to-make*course*prepara...\n","2       38798  ...  30-minutes-or-less*time-to-make*course*main-in...\n","3       35173  ...  60-minutes-or-less*time-to-make*course*prepara...\n","4       84797  ...  30-minutes-or-less*time-to-make*course*main-in...\n","...       ...  ...                                                ...\n","29995  267661  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29996  386977  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29997  103312  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29998  486161  ...  ham*60-minutes-or-less*time-to-make*course*mai...\n","29999  298512  ...  30-minutes-or-less*time-to-make*course*prepara...\n","\n","[30000 rows x 11 columns]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ejBEU9vWZ8WJ"},"source":["### npy"]},{"cell_type":"markdown","metadata":{"id":"XvCpbjbLZ8WJ"},"source":["2.1 Разделите таблицу, полученную в результате 1.5, на две таблицы: одна содержит рецепты, загруженные до 2000 года; вторая - все остальные. В полученных таблицах оставьте только числовые столбцы и преобразуйте их к `numpy.array`"]},{"cell_type":"code","metadata":{"id":"Qfbe-aX9ciyn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633961126540,"user_tz":-180,"elapsed":383,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"6546d73e-d0e3-48a7-d4d9-7889e6c5080c"},"source":["import pandas as pd\n","\n","recipes_filled[\"submitted\"] = pd.to_datetime(recipes_filled[\"submitted\"], format='%Y-%m-%d', errors='ignore')\n","\n","print(recipes_filled)\n","\n","print (recipes_filled.dtypes)\n","\n","\n","\n","recipes_before = recipes_filled[recipes_filled[\"submitted\"].dt.year < 2000]\n","print (recipes_before)\n","\n","recipes_after = recipes_filled[recipes_filled[\"submitted\"].dt.year >= 2000]\n","print (recipes_after)\n","\n","print (recipes_after.dtypes)\n","\n","\n","recipes_after_np = np.array([recipes_after[item] for item in [\"id\", \"minutes\", \"contributor_id\",\"n_steps\",\"n_ingredients\",\"n_tags\"]]) # recipes_after[[\"id\", \"minutes\"]].values\n","\n","print (recipes_after_np)\n","\n","recipes_before_np = np.array([recipes_before[item] for item in [\"id\", \"minutes\", \"contributor_id\",\"n_steps\",\"n_ingredients\",\"n_tags\"]])\n","print (recipes_before_np)\n","\n"],"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["           id  ...                                        ingredients\n","0       44123  ...  weeknight*time-to-make*course*main-ingredient*...\n","1       67664  ...  15-minutes-or-less*time-to-make*course*prepara...\n","2       38798  ...  30-minutes-or-less*time-to-make*course*main-in...\n","3       35173  ...  60-minutes-or-less*time-to-make*course*prepara...\n","4       84797  ...  30-minutes-or-less*time-to-make*course*main-in...\n","...       ...  ...                                                ...\n","29995  267661  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29996  386977  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29997  103312  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29998  486161  ...  ham*60-minutes-or-less*time-to-make*course*mai...\n","29999  298512  ...  30-minutes-or-less*time-to-make*course*prepara...\n","\n","[30000 rows x 11 columns]\n","id                         int64\n","name                      object\n","minutes                    int64\n","contributor_id             int64\n","submitted         datetime64[ns]\n","n_steps                    int64\n","description               object\n","n_ingredients              int64\n","n_tags                     int64\n","tags                      object\n","ingredients               object\n","dtype: object\n","         id  ...                                        ingredients\n","189    3441  ...  30-minutes-or-less*time-to-make*course*main-in...\n","434    4205  ...  30-minutes-or-less*time-to-make*course*main-in...\n","439    3258  ...  15-minutes-or-less*time-to-make*course*main-in...\n","669     153  ...  time-to-make*course*cuisine*preparation*north-...\n","785    5197  ...  15-minutes-or-less*time-to-make*main-ingredien...\n","...     ...  ...                                                ...\n","29196   465  ...  30-minutes-or-less*time-to-make*course*prepara...\n","29243  2889  ...  weeknight*time-to-make*course*main-ingredient*...\n","29463  3752  ...  15-minutes-or-less*time-to-make*course*prepara...\n","29662  4801  ...  15-minutes-or-less*time-to-make*course*main-in...\n","29669  2982  ...  15-minutes-or-less*time-to-make*main-ingredien...\n","\n","[275 rows x 11 columns]\n","           id  ...                                        ingredients\n","0       44123  ...  weeknight*time-to-make*course*main-ingredient*...\n","1       67664  ...  15-minutes-or-less*time-to-make*course*prepara...\n","2       38798  ...  30-minutes-or-less*time-to-make*course*main-in...\n","3       35173  ...  60-minutes-or-less*time-to-make*course*prepara...\n","4       84797  ...  30-minutes-or-less*time-to-make*course*main-in...\n","...       ...  ...                                                ...\n","29995  267661  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29996  386977  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29997  103312  ...  time-to-make*course*main-ingredient*cuisine*pr...\n","29998  486161  ...  ham*60-minutes-or-less*time-to-make*course*mai...\n","29999  298512  ...  30-minutes-or-less*time-to-make*course*prepara...\n","\n","[29725 rows x 11 columns]\n","id                         int64\n","name                      object\n","minutes                    int64\n","contributor_id             int64\n","submitted         datetime64[ns]\n","n_steps                    int64\n","description               object\n","n_ingredients              int64\n","n_tags                     int64\n","tags                      object\n","ingredients               object\n","dtype: object\n","[[ 44123  67664  38798 ... 103312 486161 298512]\n"," [    90     10     30 ...     75     60     29]\n"," [ 35193  91970   1533 ... 161745 227978 506822]\n"," [    11      3      5 ...     10      7      9]\n"," [    18     31      8 ...     20     20     10]\n"," [    18      3      8 ...     13     22     10]]\n","[[  3441   4205   3258 ...   3752   4801   2982]\n"," [    30     25      0 ...      0     20      0]\n"," [  1562   1617   1534 ...   1535   1598 124030]\n"," [     8      3      8 ...     13      4      6]\n"," [     8      5      6 ...      4      7     13]\n"," [     8      5      6 ...      4      7      7]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"MoVb4lbHZ8WJ"},"source":["2.2. Сохраните 2 полученных массива в архив `npz`. Дайте массивам читаемые имена."]},{"cell_type":"code","metadata":{"id":"FICbuuJpcjHf"},"source":["import h5py\n","import numpy as np\n","\n","my_path = \"./task_2_2.npz\"\n","np.savez(my_path, recipes_before_2000=recipes_before_np, recipes_after_2000=recipes_after_np )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NiasqVOTZ8WJ"},"source":["2.3 Считайте созданный архив и продемонстрируйте, что данные считались корректно. "]},{"cell_type":"code","metadata":{"id":"g_T9EK3Ncjgn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959565289,"user_tz":-180,"elapsed":391,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"1d13774a-fb5c-46fa-98d9-2cf6a586144e"},"source":["\n","\n","data = np.load(my_path)\n","data.files\n","\n","recipes_before_2000 = data[\"recipes_before_2000\"]\n","print (recipes_before_2000)\n","\n","\n","\n","recipes_after_2000 = data[\"recipes_after_2000\"]\n","print(recipes_after_2000)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3.4410e+03 4.2050e+03 3.2580e+03 ... 3.7520e+03 4.8010e+03 2.9820e+03]\n"," [3.0000e+01 2.5000e+01 0.0000e+00 ... 0.0000e+00 2.0000e+01 0.0000e+00]\n"," [1.5620e+03 1.6170e+03 1.5340e+03 ... 1.5350e+03 1.5980e+03 1.2403e+05]\n"," [8.0000e+00 3.0000e+00 8.0000e+00 ... 1.3000e+01 4.0000e+00 6.0000e+00]\n"," [8.0000e+00 5.0000e+00 6.0000e+00 ... 4.0000e+00 7.0000e+00        nan]\n"," [8.0000e+00 5.0000e+00 6.0000e+00 ... 4.0000e+00 7.0000e+00 7.0000e+00]]\n","[[4.41230e+04 6.76640e+04 3.87980e+04 ... 1.03312e+05 4.86161e+05\n","  2.98512e+05]\n"," [9.00000e+01 1.00000e+01 3.00000e+01 ... 7.50000e+01 6.00000e+01\n","  2.90000e+01]\n"," [3.51930e+04 9.19700e+04 1.53300e+03 ... 1.61745e+05 2.27978e+05\n","  5.06822e+05]\n"," [1.10000e+01 3.00000e+00 5.00000e+00 ... 1.00000e+01 7.00000e+00\n","  9.00000e+00]\n"," [1.80000e+01         nan 8.00000e+00 ...         nan         nan\n","  1.00000e+01]\n"," [1.80000e+01 3.00000e+00 8.00000e+00 ... 1.30000e+01 2.20000e+01\n","  1.00000e+01]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"NpXmA2TJZ8WK"},"source":["### hdf"]},{"cell_type":"markdown","metadata":{"id":"RUe4_SIqZ8WL"},"source":["3.1 Выведите названия всех датасетов, находящихся в файле `nutrition_sample.h5`, а также размерность матриц, содержащихся в данных датасетах и их метаданные.\n","\n","Формат вывода:\n","```\n","Dataset name=dataset_0, dataset size=(30000,), metadata={'info': 'calories (#)'}\n","Dataset name=dataset_1, dataset size=(30000,), metadata={'info': 'total fat (PDV)'}\n","...\n","```"]},{"cell_type":"code","metadata":{"id":"y1lp1tEKclTn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959573000,"user_tz":-180,"elapsed":431,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"c6213838-7302-4ee2-d2f0-018db8da2176"},"source":["datasets_dict = {}\n","with h5py.File(\"/content/drive/MyDrive/Colab Notebooks/lab 5/nutrition_sample.h5\",\"r\") as hdf:\n","    \n","    for key in hdf.keys():\n","        file = hdf[key]\n","        metadata = dict(file.attrs)\n","        print(f\"Dataset name={key}, dataset size={file.shape}, metadata={metadata}\")\n","        datasets_dict[key] = {\"all\" : {'data': file[:]}, 'attrs': metadata}\n","\n","\n","\n","datasets_dict\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset name=dataset_0, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'calories (#)'}\n","Dataset name=dataset_1, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}\n","Dataset name=dataset_2, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}\n","Dataset name=dataset_3, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}\n","Dataset name=dataset_4, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}\n","Dataset name=dataset_5, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}\n","Dataset name=dataset_6, dataset size=(30000, 2), metadata={'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}\n"]},{"output_type":"execute_result","data":{"text/plain":["{'dataset_0': {'all': {'data': array([[4.41230e+04, 8.04700e+02],\n","          [6.76640e+04, 1.64600e+02],\n","          [3.87980e+04, 5.38000e+01],\n","          ...,\n","          [1.03312e+05, 8.64100e+02],\n","          [4.86161e+05, 4.15200e+02],\n","          [2.98512e+05, 1.88000e+02]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'calories (#)'}},\n"," 'dataset_1': {'all': {'data': array([[4.41230e+04, 1.08000e+02],\n","          [6.76640e+04, 3.00000e+00],\n","          [3.87980e+04, 5.00000e+00],\n","          ...,\n","          [1.03312e+05, 8.70000e+01],\n","          [4.86161e+05, 2.60000e+01],\n","          [2.98512e+05, 1.10000e+01]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}},\n"," 'dataset_2': {'all': {'data': array([[4.41230e+04, 2.60000e+01],\n","          [6.76640e+04, 5.00000e+00],\n","          [3.87980e+04, 2.00000e+00],\n","          ...,\n","          [1.03312e+05, 3.00000e+01],\n","          [4.86161e+05, 3.40000e+01],\n","          [2.98512e+05, 5.70000e+01]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}},\n"," 'dataset_3': {'all': {'data': array([[4.41230e+04, 1.90000e+01],\n","          [6.76640e+04, 1.00000e+00],\n","          [3.87980e+04, 3.00000e+00],\n","          ...,\n","          [1.03312e+05, 1.80000e+01],\n","          [4.86161e+05, 2.60000e+01],\n","          [2.98512e+05, 1.10000e+01]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}},\n"," 'dataset_4': {'all': {'data': array([[4.41230e+04, 2.80000e+01],\n","          [6.76640e+04, 4.00000e+00],\n","          [3.87980e+04, 3.00000e+00],\n","          ...,\n","          [1.03312e+05, 4.00000e+01],\n","          [4.86161e+05, 4.40000e+01],\n","          [2.98512e+05, 7.00000e+00]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}},\n"," 'dataset_5': {'all': {'data': array([[4.41230e+04, 2.14000e+02],\n","          [6.76640e+04, 6.00000e+00],\n","          [3.87980e+04, 3.00000e+00],\n","          ...,\n","          [1.03312e+05, 1.52000e+02],\n","          [4.86161e+05, 2.10000e+01],\n","          [2.98512e+05, 2.10000e+01]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}},\n"," 'dataset_6': {'all': {'data': array([[4.41230e+04, 1.00000e+01],\n","          [6.76640e+04, 1.10000e+01],\n","          [3.87980e+04, 1.00000e+00],\n","          ...,\n","          [1.03312e+05, 2.30000e+01],\n","          [4.86161e+05, 1.50000e+01],\n","          [2.98512e+05, 9.00000e+00]])},\n","  'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}}}"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"4DyZTNWfZ8WM"},"source":["3.2 Разбейте каждый из имеющихся датасетов на две части: 1 часть содержит только те строки, где PDV (Percent Daily Value) превышает 100%; 2 часть содержит те строки, где PDV не составляет не более 100%. Создайте 2 группы в файле и разместите в них соответствующие части датасета c сохранением метаданных исходных датасетов. Итого должно получиться 2 группы, содержащие несколько датасетов. Сохраните результаты в файл `nutrition_grouped.h5`"]},{"cell_type":"code","metadata":{"id":"LRaaI61eckro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959590632,"user_tz":-180,"elapsed":370,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"86818060-e2a2-4c1c-ec39-0a89fb9233f0"},"source":["datasets_dict = {k : v for k, v in datasets_dict.items() if \"PDV\" in v[\"attrs\"][\"col_1\"]}\n","\n","new_datasets_dict = {\"PDV_more_100\" : {}, \"PDV_less_100\": {}}\n","for dataset, values in datasets_dict.items():\n","\n","    data = values[\"all\"][\"data\"]\n","    mask = data[:,1] > 1\n","    \n","    new_datasets_dict[\"PDV_more_100\"][dataset] = {\"data\" :  data[mask], \"attrs\" : values[\"attrs\"], \"name\": dataset}\n","\n","    mask = data[:,1] < 1\n","    new_datasets_dict[\"PDV_less_100\"][dataset] = {\"data\" :  data[mask], \"attrs\" : values[\"attrs\"], \"name\": dataset}\n","\n","\n","for dataset, data in new_datasets_dict.items():\n","    print(dataset)\n","    print(data)\n","\n","\n","\n","\n","h5_path = \"./nutrition_grouped.h5\"\n","with h5py.File(h5_path, mode='w') as hdf:\n","    for group, data in new_datasets_dict.items():\n","        new_group = hdf.create_group(group)\n","        for d in data:\n","            item = new_group.create_dataset(name=data[d]['name'], data=data[d]['data'])\n","            item.attrs.update(data[d]['attrs'])\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PDV_more_100\n","{'dataset_1': {'data': array([[4.41230e+04, 1.08000e+02],\n","       [6.76640e+04, 3.00000e+00],\n","       [3.87980e+04, 5.00000e+00],\n","       ...,\n","       [1.03312e+05, 8.70000e+01],\n","       [4.86161e+05, 2.60000e+01],\n","       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[4.41230e+04, 2.60000e+01],\n","       [6.76640e+04, 5.00000e+00],\n","       [3.87980e+04, 2.00000e+00],\n","       ...,\n","       [1.03312e+05, 3.00000e+01],\n","       [4.86161e+05, 3.40000e+01],\n","       [2.98512e+05, 5.70000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[4.41230e+04, 1.90000e+01],\n","       [3.87980e+04, 3.00000e+00],\n","       [3.51730e+04, 9.70000e+01],\n","       ...,\n","       [1.03312e+05, 1.80000e+01],\n","       [4.86161e+05, 2.60000e+01],\n","       [2.98512e+05, 1.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[4.41230e+04, 2.80000e+01],\n","       [6.76640e+04, 4.00000e+00],\n","       [3.87980e+04, 3.00000e+00],\n","       ...,\n","       [1.03312e+05, 4.00000e+01],\n","       [4.86161e+05, 4.40000e+01],\n","       [2.98512e+05, 7.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[4.41230e+04, 2.14000e+02],\n","       [6.76640e+04, 6.00000e+00],\n","       [3.87980e+04, 3.00000e+00],\n","       ...,\n","       [1.03312e+05, 1.52000e+02],\n","       [4.86161e+05, 2.10000e+01],\n","       [2.98512e+05, 2.10000e+01]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[4.41230e+04, 1.00000e+01],\n","       [6.76640e+04, 1.10000e+01],\n","       [3.51730e+04, 2.00000e+00],\n","       ...,\n","       [1.03312e+05, 2.30000e+01],\n","       [4.86161e+05, 1.50000e+01],\n","       [2.98512e+05, 9.00000e+00]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}\n","PDV_less_100\n","{'dataset_1': {'data': array([[116741.,      0.],\n","       [342619.,      0.],\n","       [173730.,      0.],\n","       ...,\n","       [279769.,      0.],\n","       [321224.,      0.],\n","       [325574.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}, 'name': 'dataset_1'}, 'dataset_2': {'data': array([[292568.,      0.],\n","       [287778.,      0.],\n","       [ 11361.,      0.],\n","       ...,\n","       [498523.,      0.],\n","       [ 86286.,      0.],\n","       [275655.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}, 'name': 'dataset_2'}, 'dataset_3': {'data': array([[296983.,      0.],\n","       [250232.,      0.],\n","       [327979.,      0.],\n","       ...,\n","       [376373.,      0.],\n","       [279769.,      0.],\n","       [162411.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}, 'name': 'dataset_3'}, 'dataset_4': {'data': array([[367987.,      0.],\n","       [100837.,      0.],\n","       [165096.,      0.],\n","       ...,\n","       [400519.,      0.],\n","       [498523.,      0.],\n","       [130433.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}, 'name': 'dataset_4'}, 'dataset_5': {'data': array([[116741.,      0.],\n","       [342619.,      0.],\n","       [173730.,      0.],\n","       ...,\n","       [321224.,      0.],\n","       [325574.,      0.],\n","       [316950.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}, 'name': 'dataset_5'}, 'dataset_6': {'data': array([[147477.,      0.],\n","       [383120.,      0.],\n","       [367987.,      0.],\n","       ...,\n","       [269904.,      0.],\n","       [205148.,      0.],\n","       [505053.,      0.]]), 'attrs': {'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}, 'name': 'dataset_6'}}\n"]}]},{"cell_type":"markdown","metadata":{"id":"IsdDVxVKZ8WM"},"source":["3.3 Выведите названия всех групп и датасетов, находящихся в этих группах, из файла `nutrition_grouped.h5` а также размерность матриц, содержащихся в датасетах и их метаданные."]},{"cell_type":"code","metadata":{"id":"I9cazehyckTr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959601914,"user_tz":-180,"elapsed":391,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"47e180de-a23d-418c-aa73-82d1df9781c1"},"source":["with h5py.File(h5_path) as hdf:\n","    \n","    for group_name, data in hdf.items():\n","        print(f'\\nGroup: {group_name}')\n","\n","        for key in data:\n","            file = data[key]\n","            metadata = dict(file.attrs)\n","            print(f\"Dataset name={key}, dataset size={file.shape}, metadata={metadata}\")\n","            datasets_dict[key] = {\"all\" : {'data': file[:]}, 'attrs': metadata}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Group: PDV_less_100\n","Dataset name=dataset_1, dataset size=(2146, 2), metadata={'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}\n","Dataset name=dataset_2, dataset size=(1371, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}\n","Dataset name=dataset_3, dataset size=(2588, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}\n","Dataset name=dataset_4, dataset size=(1274, 2), metadata={'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}\n","Dataset name=dataset_5, dataset size=(2569, 2), metadata={'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}\n","Dataset name=dataset_6, dataset size=(1653, 2), metadata={'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}\n","\n","Group: PDV_more_100\n","Dataset name=dataset_1, dataset size=(27025, 2), metadata={'col_0': 'recipe_id', 'col_1': 'total fat (PDV)'}\n","Dataset name=dataset_2, dataset size=(27822, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sugar (PDV)'}\n","Dataset name=dataset_3, dataset size=(26148, 2), metadata={'col_0': 'recipe_id', 'col_1': 'sodium (PDV)'}\n","Dataset name=dataset_4, dataset size=(27748, 2), metadata={'col_0': 'recipe_id', 'col_1': 'protein (PDV)'}\n","Dataset name=dataset_5, dataset size=(26559, 2), metadata={'col_0': 'recipe_id', 'col_1': 'saturated fat (PDV)'}\n","Dataset name=dataset_6, dataset size=(26591, 2), metadata={'col_0': 'recipe_id', 'col_1': 'carbohydrates (PDV)'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"bc6Qo-xUZ8WM"},"source":["3.4 Модифицируйте код из 3.3 таким образом, чтобы сохранить датасеты, используя сжатие. Сравните размер полученного файла с размерами файла из 3.3. Прокомментируйте результат."]},{"cell_type":"code","metadata":{"id":"6LiaSqErckD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633959654377,"user_tz":-180,"elapsed":2142,"user":{"displayName":"N.ON.E","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02771659712800707230"}},"outputId":"e3258c77-ccda-4c4f-b616-bbb4841726a8"},"source":["h5_compressed_path = \"./nutrition_grouped_compressed.h5\"\n","with h5py.File(h5_compressed_path, mode='w') as hdf:\n","    for group, data in new_datasets_dict.items():\n","        new_group = hdf.create_group(group)\n","        for d in data:\n","            item = new_group.create_dataset(name=data[d]['name'], data=data[d]['data'], compression=\"gzip\", compression_opts=9)\n","            item.attrs.update(data[d]['attrs'])\n","\n","\n","def get_file_size_2(file):\n"," \n","    stat = os.stat(file)\n","    print(stat)\n","    size = stat.st_size\n","    return size\n","\n","def convert_bytes(size, unit=None):\n","    if unit == \"KB\":\n","        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n","    elif unit == \"MB\":\n","        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n","    elif unit == \"GB\":\n","        return print('File size: ' + str(round(size / (1024 * 1024 * 1024), 3)) + ' Gigabytes')\n","    else:\n","        return print('File size: ' + str(size) + ' bytes')\n","\n","\n","import os\n","\n","\n","size = get_file_size_2(h5_path)\n","print('File size: ' + str(size) + ' bytes')\n","\n","size = get_file_size_2(h5_compressed_path)\n","print('File size: ' + str(size) + ' bytes')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["os.stat_result(st_mode=33188, st_ino=3801228, st_dev=51, st_nlink=1, st_uid=0, st_gid=0, st_size=2788576, st_atime=1633959601, st_mtime=1633959590, st_ctime=1633959590)\n","File size: 2788576 bytes\n","os.stat_result(st_mode=33188, st_ino=3801229, st_dev=51, st_nlink=1, st_uid=0, st_gid=0, st_size=914789, st_atime=1633959652, st_mtime=1633959653, st_ctime=1633959653)\n","File size: 914789 bytes\n"]}]}]}