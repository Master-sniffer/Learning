{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyopencl"
      ],
      "metadata": {
        "id": "ZC7aZntvM7Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxuvfETYMvGK",
        "outputId": "8d01ca95-cd1d-4de2-dc02-f201a8cce12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31.] [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81. 100. 121. 144. 169.\n",
            " 196. 225. 256. 289. 324. 361. 400. 441. 484. 529. 576. 625. 676. 729.\n",
            " 784. 841. 900. 961.]\n"
          ]
        }
      ],
      "source": [
        "import pyopencl as cl\n",
        "import numpy as np\n",
        "\n",
        "a = np.arange(32).astype(np.float32)\n",
        "res = np.empty_like(a)\n",
        "\n",
        "platform = cl.get_platforms()\n",
        "my_gpu_devices = platform[0].get_devices(device_type=cl.device_type.GPU)\n",
        "ctx = cl.Context(devices=my_gpu_devices)\n",
        "\n",
        "\n",
        "#ctx = cl.create_some_context()\n",
        "queue = cl.CommandQueue(ctx)\n",
        "\n",
        "mf = cl.mem_flags\n",
        "a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
        "dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, res.nbytes)\n",
        "\n",
        "prg = cl.Program(ctx, \"\"\"\n",
        "    __kernel void sq(__global const float *a,\n",
        "    __global float *c)\n",
        "    {\n",
        "      int gid = get_global_id(0);\n",
        "      c[gid] = a[gid] * a[gid];\n",
        "    }\n",
        "    \"\"\").build()\n",
        "\n",
        "prg.sq(queue, a.shape, None, a_buf, dest_buf)\n",
        "\n",
        "cl.enqueue_copy(queue, res, dest_buf)\n",
        "\n",
        "print (a, res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyopencl as cl\n",
        "import numpy as np\n",
        "from imageio import imread, imsave\n",
        "\n",
        "# Read in image\n",
        "img = imread(\"noisyImage.jpg\").astype(np.float32)\n",
        "print(img.shape)\n",
        "img = np.mean(img, axis=2)\n",
        "print(img.shape)\n",
        "\n",
        "ctx = cl.create_some_context()\n",
        "queue = cl.CommandQueue(ctx)\n",
        "\n",
        "mf = cl.mem_flags\n",
        "\n",
        "# Kernel function\n",
        "src = \"\"\"\n",
        "void sort(int *a, int *b, int *c) {\n",
        "   int swap;\n",
        "   if(*a > *b) {\n",
        "      swap = *a;\n",
        "      *a = *b;\n",
        "      *b = swap;\n",
        "   }\n",
        "   if(*a > *c) {\n",
        "      swap = *a;\n",
        "      *a = *c;\n",
        "      *c = swap;\n",
        "   }\n",
        "   if(*b > *c) {\n",
        "      swap = *b;\n",
        "      *b = *c;\n",
        "      *c = swap;\n",
        "   }\n",
        "}\n",
        "__kernel void medianFilter(\n",
        "    __global float *img, __global float *result, __global int *width, __global\n",
        "    int *height)\n",
        "{\n",
        "    int w = *width;\n",
        "    int h = *height;\n",
        "    int posx = get_global_id(1);\n",
        "    int posy = get_global_id(0);\n",
        "    int i = w*posy + posx;\n",
        "    // Keeping the edge pixels the same\n",
        "    if( posx == 0 || posy == 0 || posx == w-1 || posy == h-1 )\n",
        "    {\n",
        "        result[i] = img[i];\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        int pixel00, pixel01, pixel02, pixel10, pixel11, pixel12, pixel20,\n",
        "            pixel21, pixel22;\n",
        "        pixel00 = img[i - 1 - w];\n",
        "        pixel01 = img[i- w];\n",
        "        pixel02 = img[i + 1 - w];\n",
        "        pixel10 = img[i - 1];\n",
        "        pixel11 = img[i];\n",
        "        pixel12 = img[i + 1];\n",
        "        pixel20 = img[i - 1 + w];\n",
        "        pixel21 = img[i + w];\n",
        "        pixel22 = img[i + 1 + w];\n",
        "        //sort the rows\n",
        "        sort( &(pixel00), &(pixel01), &(pixel02) );\n",
        "        sort( &(pixel10), &(pixel11), &(pixel12) );\n",
        "        sort( &(pixel20), &(pixel21), &(pixel22) );\n",
        "        //sort the columns\n",
        "        sort( &(pixel00), &(pixel10), &(pixel20) );\n",
        "        sort( &(pixel01), &(pixel11), &(pixel21) );\n",
        "        sort( &(pixel02), &(pixel12), &(pixel22) );\n",
        "        //sort the diagonal\n",
        "        sort( &(pixel00), &(pixel11), &(pixel22) );\n",
        "        // median is the the middle value of the diagonal\n",
        "        result[i] = pixel11;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Kernel function instantiation\n",
        "prg = cl.Program(ctx, src).build()\n",
        "# Allocate memory for variables on the device\n",
        "img_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=img)\n",
        "result_g = cl.Buffer(ctx, mf.WRITE_ONLY, img.nbytes)\n",
        "width_g = cl.Buffer(\n",
        "    ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=np.int32(img.shape[1])\n",
        ")\n",
        "height_g = cl.Buffer(\n",
        "    ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=np.int32(img.shape[0])\n",
        ")\n",
        "# Call Kernel. Automatically takes care of block/grid distribution\n",
        "prg.medianFilter(queue, img.shape, None, img_g, result_g, width_g, height_g)\n",
        "result = np.empty_like(img)\n",
        "cl.enqueue_copy(queue, result, result_g)\n",
        "\n",
        "# Show the blurred image\n",
        "imsave(\"medianFilter-OpenCL.jpg\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF-Qeq_MM8oq",
        "outputId": "f2202712-c6b9-4710-b111-68486c258ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(510, 512, 3)\n",
            "(510, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [12.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example provided by Eilif Muller\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "KERNEL_CODE = \"\"\"\n",
        "\n",
        "// Thread block size\n",
        "#define BLOCK_SIZE %(block_size)d\n",
        "\n",
        "// Matrix dimensions\n",
        "// (chosen as multiples of the thread block size for simplicity)\n",
        "#define WA %(w_a)d // Matrix A width\n",
        "#define HA %(h_a)d // Matrix A height\n",
        "#define WB %(w_b)d // Matrix B width\n",
        "#define HB WA  // Matrix B height\n",
        "#define WC WB  // Matrix C width\n",
        "#define HC HA  // Matrix C height\n",
        "\n",
        "\n",
        "/*\n",
        " * Copyright 1993-2009 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
        " * proprietary rights in and to this software and related documentation.\n",
        " * Any use, reproduction, disclosure, or distribution of this software\n",
        " * and related documentation without an express license agreement from\n",
        " * NVIDIA Corporation is strictly prohibited.\n",
        " *\n",
        " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
        " * associated with this source code for terms and conditions that govern\n",
        " * your use of this NVIDIA software.\n",
        " *\n",
        " */\n",
        "\n",
        "/* Matrix multiplication: C = A * B.\n",
        " * Device code.\n",
        " */\n",
        "\n",
        "#define AS(j, i) As[i + j * BLOCK_SIZE]\n",
        "#define BS(j, i) Bs[i + j * BLOCK_SIZE]\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "//! Matrix multiplication on the device: C = A * B\n",
        "//! WA is A's width and WB is B's width\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "__kernel __attribute__((reqd_work_group_size(16,16,1))) \n",
        "void\n",
        "matrixMul( __global float* C, __global float* A, __global float* B)\n",
        "{\n",
        "    __local float As[BLOCK_SIZE*BLOCK_SIZE];\n",
        "    __local float Bs[BLOCK_SIZE*BLOCK_SIZE];\n",
        "\n",
        "    // Block index\n",
        "    int bx = get_group_id(0);\n",
        "    int by = get_group_id(1);\n",
        "\n",
        "    // Thread index\n",
        "    int tx = get_local_id(0);\n",
        "    int ty = get_local_id(1);\n",
        "\n",
        "    // Index of the first sub-matrix of A processed by the block\n",
        "    int aBegin = WA * BLOCK_SIZE * by;\n",
        "\n",
        "    // Index of the last sub-matrix of A processed by the block\n",
        "    int aEnd   = aBegin + WA - 1;\n",
        "\n",
        "    // Step size used to iterate through the sub-matrices of A\n",
        "    int aStep  = BLOCK_SIZE;\n",
        "\n",
        "    // Index of the first sub-matrix of B processed by the block\n",
        "    int bBegin = BLOCK_SIZE * bx;\n",
        "\n",
        "    // Step size used to iterate through the sub-matrices of B\n",
        "    int bStep  = BLOCK_SIZE * WB;\n",
        "\n",
        "    // Csub is used to store the element of the block sub-matrix\n",
        "    // that is computed by the thread\n",
        "    float Csub = 0.0f;\n",
        "\n",
        "    // Loop over all the sub-matrices of A and B\n",
        "    // required to compute the block sub-matrix\n",
        "    for (int a = aBegin, b = bBegin;\n",
        "             a <= aEnd;\n",
        "             a += aStep, b += bStep) {\n",
        "\n",
        "        // Load the matrices from device memory\n",
        "        // to shared memory; each thread loads\n",
        "        // one element of each matrix\n",
        "        AS(ty, tx) = A[a + WA * ty + tx];\n",
        "        BS(ty, tx) = B[b + WB * ty + tx];\n",
        "\n",
        "        // Synchronize to make sure the matrices are loaded\n",
        "        barrier(CLK_LOCAL_MEM_FENCE);\n",
        "\n",
        "        // Multiply the two matrices together;\n",
        "        // each thread computes one element\n",
        "        // of the block sub-matrix\n",
        "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
        "            Csub += AS(ty, k) * BS(k, tx);\n",
        "\n",
        "        // Synchronize to make sure that the preceding\n",
        "        // computation is done before loading two new\n",
        "        // sub-matrices of A and B in the next iteration\n",
        "        barrier(CLK_LOCAL_MEM_FENCE);\n",
        "    }\n",
        "\n",
        "    // Write the block sub-matrix to device memory;\n",
        "    // each thread writes one element\n",
        "    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
        "\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import pyopencl as cl\n",
        "from time import time\n",
        "import numpy\n",
        "\n",
        "block_size = 16\n",
        "\n",
        "ctx = cl.create_some_context()\n",
        "\n",
        "for dev in ctx.devices:\n",
        "    assert dev.local_mem_size > 0\n",
        "\n",
        "queue = cl.CommandQueue(ctx,\n",
        "        properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
        "\n",
        "#queue = cl.CommandQueue(ctx)\n",
        "\n",
        "if False:\n",
        "    a_height = 4096\n",
        "    #a_height = 1024\n",
        "    a_width = 2048\n",
        "    #a_width = 256\n",
        "    #b_height == a_width\n",
        "    b_width = a_height\n",
        "\n",
        "elif False:\n",
        "    # like PyCUDA\n",
        "    a_height = 2516\n",
        "    a_width = 1472\n",
        "    b_height = a_width\n",
        "    b_width = 2144\n",
        "\n",
        "else:\n",
        "    # CL SDK\n",
        "    a_width = 50*block_size\n",
        "    a_height = 100*block_size\n",
        "    b_width = 50*block_size\n",
        "    b_height = a_width\n",
        "\n",
        "c_width = b_width\n",
        "c_height = a_height\n",
        "\n",
        "h_a = numpy.random.rand(a_height, a_width).astype(numpy.float32)\n",
        "h_b = numpy.random.rand(b_height, b_width).astype(numpy.float32)\n",
        "h_c = numpy.empty((c_height, c_width)).astype(numpy.float32)\n",
        "\n",
        "\n",
        "kernel_params = {\"block_size\": block_size,\n",
        "        \"w_a\":a_width, \"h_a\":a_height, \"w_b\":b_width}\n",
        "\n",
        "prg = cl.Program(ctx, KERNEL_CODE % kernel_params,\n",
        "        ).build(options=\"-cl-mad-enable -cl-fast-relaxed-math\")\n",
        "kernel = prg.matrixMul\n",
        "#print prg.binaries[0]\n",
        "\n",
        "assert a_width % block_size == 0\n",
        "assert a_height % block_size == 0\n",
        "assert b_width % block_size == 0\n",
        "\n",
        "# transfer host -> device -----------------------------------------------------\n",
        "mf = cl.mem_flags\n",
        "\n",
        "t1 = time()\n",
        "\n",
        "d_a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_a)\n",
        "d_b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_b)\n",
        "d_c_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=h_c.nbytes)\n",
        "\n",
        "push_time = time()-t1\n",
        "\n",
        "# warmup ----------------------------------------------------------------------\n",
        "for i in range(5):\n",
        "    event = kernel(queue, h_c.shape, (block_size, block_size), \n",
        "            d_c_buf, d_a_buf, d_b_buf)\n",
        "    event.wait()\n",
        "\n",
        "queue.finish()\n",
        "\n",
        "# actual benchmark ------------------------------------------------------------\n",
        "t1 = time()\n",
        "\n",
        "count = 20\n",
        "for i in range(count):\n",
        "    event = kernel(queue, h_c.shape, (block_size, block_size),\n",
        "            d_c_buf, d_a_buf, d_b_buf)\n",
        "\n",
        "event.wait()\n",
        "\n",
        "gpu_time = (time()-t1)/count\n",
        "\n",
        "# transfer device -> host -----------------------------------------------------\n",
        "t1 = time()\n",
        "#cl.enqueue_read_buffer(queue, d_c_buf, h_c).wait()\n",
        "pull_time = time()-t1\n",
        "\n",
        "# timing output ---------------------------------------------------------------\n",
        "gpu_total_time = gpu_time+push_time+pull_time\n",
        "\n",
        "print (\"GPU push+compute+pull total [s]:\", gpu_total_time)\n",
        "print (\"GPU push [s]:\", push_time)\n",
        "print (\"GPU pull [s]:\", pull_time)\n",
        "print (\"GPU compute (host-timed) [s]:\", gpu_time)\n",
        "print (\"GPU compute (event-timed) [s]: \", (event.profile.end-event.profile.start)*1e-9)\n",
        "\n",
        "gflop = h_c.size * (a_width * 2.) / (1000**3.)\n",
        "gflops = gflop / gpu_time\n",
        "\n",
        "\n",
        "print (\"GFlops/s:\", gflops)\n",
        "\n",
        "# cpu comparison --------------------------------------------------------------\n",
        "t1 = time()\n",
        "h_c_cpu = numpy.dot(h_a,h_b)\n",
        "cpu_time = time()-t1\n",
        "\n",
        "print (\"GPU==CPU:\",numpy.allclose(h_c, h_c_cpu))\n",
        "\n",
        "print (\"CPU time (s)\", cpu_time)\n",
        "\n",
        "print (\"GPU speedup (with transfer): \", cpu_time/gpu_total_time)\n",
        "print (\"GPU speedup (without transfer): \", cpu_time/gpu_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-CJFco8O7kN",
        "outputId": "444f194b-e360-487d-f092-7af6986b10fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU push+compute+pull total [s]: 0.009349071979522705\n",
            "GPU push [s]: 0.0024356842041015625\n",
            "GPU pull [s]: 2.4080276489257812e-05\n",
            "GPU compute (host-timed) [s]: 0.006889307498931884\n",
            "GPU compute (event-timed) [s]:  0.006359040000000001\n",
            "GFlops/s: 297.27225854231665\n",
            "GPU==CPU: False\n",
            "CPU time (s) 0.07741475105285645\n",
            "GPU speedup (with transfer):  8.280474385309917\n",
            "GPU speedup (without transfer):  11.23694232908878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GHI7WnePrB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}